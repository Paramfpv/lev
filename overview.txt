

This project implements a personal AI system with data ingestion, embedding generation, semantic retrieval, and early-stage memory capabilities.
Copilot should use this file to understand how all files work together and what the system is trying to achieve.

## **Main Goal**

Create a system where:

1. Data is ingested from various sources.
2. Data is cleaned, chunked, embedded, and stored.
3. User queries retrieve relevant information via semantic search.
4. Eventually support users, projects, chats, long-term memory, and persistent context.

The current repo is the prototype engine.

---

## **Current File Responsibilities**

### **data_ingestion_pipeline.py**

* Takes raw documents from `protocols_data/`
* Cleans text, removes noise, chunks it into sections
* Generates embeddings for each chunk
* Stores processed chunks into `processed_data/`
* Sends embeddings + metadata to vector storage (local/remote)
* This file is the entry point for building the knowledge base.

### **retrieval_pipeline.py**

* Handles semantic search.
* Takes a query, embeds it, performs similarity search.
* Loads relevant chunks from processed data or vector DB.
* Returns top-k results for the LLM to use.
* Will later integrate with chat history + memory system.

### **supabase_utils.py**

* Wrapper for interacting with Supabase.
* Used to store metadata, embeddings, or future user data.
* Will later handle:

  * users
  * projects
  * chats
  * memory storage
* The intention is to abstract storage away from the core engine.

### **api.py**

* Prototype API layer for interacting with ingestion + retrieval.
* Eventually becomes a FastAPI server handling:

  * sending messages
  * retrieving context
  * connecting to the memory pipeline
  * managing users & projects
* Currently minimal but central to future expansion.

### **app.py**

* Streamlit prototype UI.
* Used for testing ingestion, retrieval, and conversational flow.
* Not a production frontend — debugging and validation only.

### **main.py**

* Central entry point for executing different pipelines.
* Developer playground for connecting ingestion, retrieval, and API.

### **processed_data/**

* Contains cleaned and chunked documents.
* Output of ingestion.
* Directly used by retrieval pipeline.

### **protocols_data/**

* Raw documents.
* These are the source data that ingestion processes.

---

## **Intended Architecture (Not fully implemented yet)**

### **Core engine**

* embedding generation
* retrieval
* memory extraction
* summarization

### **Backend**

* Supabase for structured storage
* vector DB for embeddings
* eventually user accounts + project separation

### **App layer**

* Streamlit for development
* Later a proper frontend (Next.js)

### **Future Worker**

* Background jobs for embeddings
* Memory compression
* Project-based long-term memory

---

## **Planned Evolution**

Copilot should assume future code will move toward this structure:

```
/core      -> embeddings, retrieval, memory
/backend   -> supabase, vector DB, auth
/app       -> UI + handlers
/config    -> env + settings
```

The goal is to slowly refactor the current code into that layout.
Current code is monolithic; future design will be modular.

---

## **Behavior Copilot Should Aim For**

When generating or updating code:

1. Keep ingestion, retrieval, and memory logic modular.
2. Avoid mixing UI logic with core logic.
3. Use Supabase utilities for all persistent storage.
4. Keep things scalable: small functions, clear separation.
5. Maintain the long-term goal of users → projects → chats → memory.
6. Avoid tightly coupling API, UI, and core logic.
7. Keep vector search abstract so DB can change later.

---

## **Summary for Copilot**

This repository is the foundation for a personal AI with:

* document ingestion
* semantic retrieval
* structured memory
* modular backend
* future user management

Copilot should help maintain clean separation between pipelines and storage, and slowly refactor the codebase toward the intended multi-layer architecture.

---

If you want, I can generate:

* a simplified version
* a more detailed engineering spec
* one specifically optimized for future refactoring steps
